{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "curious-simpson",
   "metadata": {},
   "source": [
    "# Sentence Extraction from PMC articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "frequent-redhead",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lexas.sentence\n",
    "import lexas.relation_extraction\n",
    "import torch\n",
    "\n",
    "# Define the device to be used\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "demographic-greek",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34d9dfd5776f450ea0ff0f15f60f410b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 1: Extracting result sections from the articles\n",
    "# The 'extract_results' function is used to extract sections of results from articles.\n",
    "lexas.sentence.extract_results(\n",
    "    article_dir=\"./articles/\",\n",
    "    output_file=\"./data/result_sections.txt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "signal-annex",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing dictionaries...\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a45101371d9c4e189de913023f04c254",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 2: Masking gene terms and experiments\n",
    "# The 'mask_gene_experiment' function is used to replace gene terms and experiments with MASK tokens in the text.\n",
    "lexas.sentence.mask_gene_experiment(\n",
    "    input_file_path=\"./data/result_sections.txt\",\n",
    "    output_file_path=\"./data/masked_sentences.txt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "actual-cookbook",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "764it [01:30,  8.48it/s]\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Relation extraction using BioBERT\n",
    "# The 'predict' function is used to predict relations using BioBERT model on the masked sentences.\n",
    "lexas.relation_extraction.predict(\n",
    "    device=device,\n",
    "    input_filepath=\"./data/masked_sentences.txt\",\n",
    "    output_filepath=\"./data/masked_sentences_bert.txt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "computational-panel",
   "metadata": {},
   "source": [
    "# Prediction model for genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "economic-campaign",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lexas.prediction\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eleven-uruguay",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "455it [00:00, 172270.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Extracting context from experiments\n",
    "# The 'extract_context_from_experiments' function processes the BioBERT predictions\n",
    "# and extracts the context in which each experiment mention was made.\n",
    "lexas.prediction.extract_context_from_experiments(\n",
    "    input_file=\"./data/masked_sentences_bert.txt\",\n",
    "    output_file=\"./data/experiments_for_xgboost.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "noble-contrast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Loading feature data\n",
    "# The 'feature_load' function is used to load feature data from various resources.\n",
    "lexas.prediction.feature_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "valuable-synthesis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of features:  ['10p', '10q', '11p', '11q', '12p', '12q', '13q', '14p', '14q', '15q']\n",
      "\n",
      "Features assigned to a gene:  ['10q', 'GO:0046686', 'GO:0065003', 'GO:0005634', 'GO:0030261', 'GO:0004674', 'GO:0000086', 'GO:0007098', 'GO:0060045', 'GO:0006281']\n",
      "\n",
      "Numerical features assigned to a gene:  dict_keys(['Tissue_expression', 'Cancer_expression', 'DepMap', 'Word2Vec'])\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Selecting features\n",
    "# The 'select_features' function is used to select the features to be used in the model.\n",
    "cat_use = ['Chromosome', 'GO', 'MGI', 'HPO', 'OMIM', 'TF', 'iRefIndex', 'Localization', 'WebSter']\n",
    "num_use = ['Tissue_expression', 'Cancer_expression', 'DepMap', 'Word2Vec']\n",
    "plus = [\"String\",\"Funcoup\",\"GOSemSim\"]\n",
    "feature_list, gene_cat, gene_num = lexas.prediction.select_features(cat_use, num_use)\n",
    "\n",
    "# Print feature information\n",
    "print(\"List of features: \", feature_list[:10])\n",
    "print(\"\\nFeatures assigned to a gene: \", gene_cat[\"CDK1\"][:10])\n",
    "print(\"\\nNumerical features assigned to a gene: \", gene_num.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "union-suggestion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing CSR matrix...  Done\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Constructing the CSR matrix\n",
    "# The 'construct_csr_matrix' function is used to transform the data into a format that can be processed by the XGBoost model.\n",
    "posi_tuple, nega_tuple = lexas.prediction.generate_experiment_tuples(path_to_csv, 1990, 2021, negative_sampling=3)\n",
    "X, y = lexas.prediction.construct_csr_matrix(posi_tuple, nega_tuple, gene_cat, feature_list, gene_num, additional_features=plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "developmental-photography",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Train-Test split\n",
    "# The train_test_split function is used to split the data into training and testing sets for model training and evaluation.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "patient-double",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:03:35] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.68504\n",
      "[1]\tvalidation_0-logloss:0.67846\n",
      "[2]\tvalidation_0-logloss:0.67326\n",
      "[3]\tvalidation_0-logloss:0.66693\n",
      "[4]\tvalidation_0-logloss:0.66131\n",
      "[5]\tvalidation_0-logloss:0.65650\n",
      "[6]\tvalidation_0-logloss:0.65148\n",
      "[7]\tvalidation_0-logloss:0.64710\n",
      "[8]\tvalidation_0-logloss:0.64310\n",
      "[9]\tvalidation_0-logloss:0.63918\n",
      "[10]\tvalidation_0-logloss:0.63690\n",
      "[11]\tvalidation_0-logloss:0.63330\n",
      "[12]\tvalidation_0-logloss:0.62897\n",
      "[13]\tvalidation_0-logloss:0.62554\n",
      "[14]\tvalidation_0-logloss:0.62268\n",
      "[15]\tvalidation_0-logloss:0.61899\n",
      "[16]\tvalidation_0-logloss:0.61661\n",
      "[17]\tvalidation_0-logloss:0.61360\n",
      "[18]\tvalidation_0-logloss:0.61155\n",
      "[19]\tvalidation_0-logloss:0.60876\n",
      "[20]\tvalidation_0-logloss:0.60703\n",
      "[21]\tvalidation_0-logloss:0.60226\n",
      "[22]\tvalidation_0-logloss:0.60157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23]\tvalidation_0-logloss:0.59998\n",
      "[24]\tvalidation_0-logloss:0.59813\n",
      "[25]\tvalidation_0-logloss:0.59750\n",
      "[26]\tvalidation_0-logloss:0.59669\n",
      "[27]\tvalidation_0-logloss:0.59548\n",
      "[28]\tvalidation_0-logloss:0.59278\n",
      "[29]\tvalidation_0-logloss:0.58873\n",
      "[30]\tvalidation_0-logloss:0.58810\n",
      "[31]\tvalidation_0-logloss:0.58652\n",
      "[32]\tvalidation_0-logloss:0.58852\n",
      "[33]\tvalidation_0-logloss:0.58574\n",
      "[34]\tvalidation_0-logloss:0.58396\n",
      "[35]\tvalidation_0-logloss:0.58206\n",
      "[36]\tvalidation_0-logloss:0.57975\n",
      "[37]\tvalidation_0-logloss:0.58184\n",
      "[38]\tvalidation_0-logloss:0.58252\n",
      "[39]\tvalidation_0-logloss:0.58183\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Model Training\n",
    "# The XGBClassifier is used to train a model on the data. The model is then saved using the pickle library.\n",
    "model = xgb.XGBClassifier(\n",
    "    objective= \"binary:logistic\",\n",
    "    alpha=1e-3, \n",
    "    min_child_weight=3,\n",
    "    max_depth=10,\n",
    "    n_estimators=40000,\n",
    "    n_jobs=-1,\n",
    "    eta=0.03\n",
    ")\n",
    "model.fit(X_train, y_train, early_stopping_rounds=3, eval_set=[[X_test, y_test]])\n",
    "pickle.dump(model, open(\"./model/xgboost.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smoking-relationship",
   "metadata": {},
   "source": [
    "# Gene prediction for the next experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "measured-financing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import lexas.prediction\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load model\n",
    "# The 'pickle.load' function is used to load the previously saved XGBoost model.\n",
    "model_filepath = \"./model/xgboost.pickle\"\n",
    "if os.path.exists(model_filepath):\n",
    "    model = pickle.load(open(model_filepath,\"rb\"))\n",
    "else:\n",
    "    raise Exception(\"Model file does not exist: \" + model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "encouraging-margin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Generate scores\n",
    "# The 'generate_scores' function is used to score all genes in relation to the query using the XGBoost model.\n",
    "query = \"CEP63\"\n",
    "models = {\"xgboost\": model}\n",
    "scores = lexas.prediction.generate_scores(query, models, gene_cat, feature_list, gene_num, additional_features=plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "chinese-asbestos",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>xgboost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2939</th>\n",
       "      <td>CEP63</td>\n",
       "      <td>0.736764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2937</th>\n",
       "      <td>CEP57</td>\n",
       "      <td>0.699700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2913</th>\n",
       "      <td>CENPJ</td>\n",
       "      <td>0.690875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2941</th>\n",
       "      <td>CEP70</td>\n",
       "      <td>0.663008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3080</th>\n",
       "      <td>CHCHD2</td>\n",
       "      <td>0.645934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22507</th>\n",
       "      <td>NBN</td>\n",
       "      <td>0.625187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797</th>\n",
       "      <td>BUB1</td>\n",
       "      <td>0.625187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12328</th>\n",
       "      <td>NDE1</td>\n",
       "      <td>0.618029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7682</th>\n",
       "      <td>HSPA8</td>\n",
       "      <td>0.616741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12933</th>\n",
       "      <td>NUP62</td>\n",
       "      <td>0.616092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Symbol   xgboost\n",
       "2939    CEP63  0.736764\n",
       "2937    CEP57  0.699700\n",
       "2913    CENPJ  0.690875\n",
       "2941    CEP70  0.663008\n",
       "3080   CHCHD2  0.645934\n",
       "22507     NBN  0.625187\n",
       "1797     BUB1  0.625187\n",
       "12328    NDE1  0.618029\n",
       "7682    HSPA8  0.616741\n",
       "12933   NUP62  0.616092"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Display result\n",
    "# The result is displayed as a DataFrame sorted by the XGBoost score in descending order.\n",
    "df = pd.DataFrame(scores)\n",
    "df.sort_values(\"xgboost\", ascending=False)[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
