{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "curious-simpson",
   "metadata": {},
   "source": [
    "# Sentence Extraction from PMC articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "frequent-redhead",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import lexas.sentence\n",
    "article_dir = \"./articles/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "seeing-administration",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:06<00:00,  1.11it/s]\n"
     ]
    }
   ],
   "source": [
    "#Result extraction\n",
    "import os\n",
    "with open(\"./data/result_sections.txt\", \"w\") as f:\n",
    "    for file in tqdm.tqdm(os.listdir(article_dir)):\n",
    "        pmcid = file.split(\".\")[0]\n",
    "        year,sentences = lexas.sentence.parse(os.path.join(article_dir,file))\n",
    "        segmented_sentences = lexas.sentence.segmentation(sentences)\n",
    "        if year != 0:\n",
    "            f.write(\"\\t\".join([year, pmcid, segmented_sentences]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "simple-general",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00, 74.46it/s]\n"
     ]
    }
   ],
   "source": [
    "#Masking gene terms and experiments\n",
    "dic_hgnc,dic_expe = lexas.sentence.initialize_dictionaries()\n",
    "with open(\"./data/masked_sentences.txt\", \"w\") as f:\n",
    "    with open(\"./data/result_sections.txt\", \"r\") as f2:    \n",
    "        for line in tqdm.tqdm(f2):\n",
    "            year,pmcid,sentences = line.strip(\"\\n\").split(\"\\t\")\n",
    "            for sentence in sentences.split(\"#####\"):\n",
    "                masked = lexas.sentence.mask(sentence,dic_hgnc,dic_expe)\n",
    "                for m in masked:\n",
    "                    f.write(\"\\t\".join([year,pmcid] + m[1:3]+[sentence] + m[0:1])+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "respected-chicago",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Relation extraction using bio-BERT\n",
    "import lexas.relation_extraction\n",
    "import torch\n",
    "device=torch.device(\"cpu\")#device=torch.device(\"cuda\")\n",
    "input_file=\"./data/masked_sentences.txt\"\n",
    "output_file=\"./data/masked_sentences_bert.txt\"\n",
    "\n",
    "lexas.relation_extraction.predict(device,input_file,output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "computational-panel",
   "metadata": {},
   "source": [
    "# Prediction model for genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "satisfied-merchandise",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lexas.prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "qualified-southwest",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lexas' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f26b619d2535>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./data/masked_sentences_bert.txt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moutput_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./data/experiments_for_xgboost.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlexas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'lexas' is not defined"
     ]
    }
   ],
   "source": [
    "#Extraction of experment_context\n",
    "input_file=\"./data/masked_sentences_bert.txt\"\n",
    "output_file=\"./data/experiments_for_xgboost.csv\"\n",
    "lexas.prediction.experiment_context(input_file,output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "mobile-associate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading categorical features...\n",
      "Loading numerical features...\n",
      "Loading STRING...\n"
     ]
    }
   ],
   "source": [
    "#Loading features\n",
    "lexas.prediction.feature_load()\n",
    "symbols = lexas.prediction.symbols\n",
    "\n",
    "cat_use = ['Chromosome', 'GO', 'MGI', 'HPO', 'OMIM', 'TF', 'iRefIndex', 'Localization', 'WebSter']\n",
    "num_use = ['Tissue_expression', 'Cancer_expression', 'DepMap', 'Word2Vec']\n",
    "\n",
    "feature_list,all_cat,cat_num,all_num = lexas.prediction.choose_feature(cat_use,num_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dense-brighton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing CSR matrix...  Done\n",
      "Constructing CSR matrix...  Done\n"
     ]
    }
   ],
   "source": [
    "#Constracting csr matrix\n",
    "path_to_csv =\"./data/experiments_for_xgboost.csv\"\n",
    "\n",
    "#Experiment tuples for training \n",
    "#from 2010-2020\n",
    "#Return tuples of positive examples and 10 times the number of negative examples\n",
    "posi_tuple,nega_tuple = lexas.prediction.make_tuple(path_to_csv,2010,2020,sampling=None)\n",
    "\n",
    "#Experiment tuples for validation\n",
    "#from 2021-2023\n",
    "posi_tuple_dev,nega_tuple_dev = lexas.prediction.make_tuple(path_to_csv,2021,2023,sampling=None)\n",
    "\n",
    "#Constructing CSR sparse matrix for training\n",
    "X,y = lexas.prediction.make_csr(posi_tuple,nega_tuple,all_cat,cat_num,all_num)\n",
    "X_dev,y_dev = lexas.prediction.make_csr(posi_tuple_dev,nega_tuple_dev,all_cat,cat_num,all_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "vertical-allergy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.6839728564638003\n"
     ]
    }
   ],
   "source": [
    "#Training a SVM model\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "import pickle\n",
    "\n",
    "reg = 0.001\n",
    "lrn = SGDClassifier(loss='hinge', alpha=reg,penalty='l2')\n",
    "lrn.fit(X,y)\n",
    "calibrator = CalibratedClassifierCV(lrn, cv='prefit')\n",
    "model=calibrator.fit(X,y)\n",
    "pickle.dump(model, open(\"./model/svm_{}.pickle\".format(reg), \"wb\"))\n",
    "\n",
    "#AUC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "y_pred = model.predict_proba(X_dev)[:,1]\n",
    "print(\"AUC:\",roc_auc_score(y_dev,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "systematic-philosophy",
   "metadata": {},
   "source": [
    "# Gene prediction for the next experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "excellent-contrast",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Before running, please load the features\n",
    "import os\n",
    "import lexas.prediction\n",
    "import pickle\n",
    "model = pickle.load(open(\"./model/svm_0.001.pickle\",\"rb\"))\n",
    "models={\"svm-0.01\":model}\n",
    "query=\"CEP57\"\n",
    "\n",
    "scores = lexas.prediction.scoring(query,models,all_cat,cat_num,all_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "younger-finding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>svm-0.01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1BG</td>\n",
       "      <td>0.137148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A1BG-AS1</td>\n",
       "      <td>0.042312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1CF</td>\n",
       "      <td>0.061554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A2M</td>\n",
       "      <td>0.024529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A2ML1</td>\n",
       "      <td>0.013632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22938</th>\n",
       "      <td>PEPN</td>\n",
       "      <td>0.042129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22939</th>\n",
       "      <td>PYK</td>\n",
       "      <td>0.042086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22940</th>\n",
       "      <td>TAX</td>\n",
       "      <td>0.148369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22941</th>\n",
       "      <td>TMPRSS3</td>\n",
       "      <td>0.015149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22942</th>\n",
       "      <td>XAGE1E</td>\n",
       "      <td>0.041072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22943 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Symbol  svm-0.01\n",
       "0          A1BG  0.137148\n",
       "1      A1BG-AS1  0.042312\n",
       "2          A1CF  0.061554\n",
       "3           A2M  0.024529\n",
       "4         A2ML1  0.013632\n",
       "...         ...       ...\n",
       "22938      PEPN  0.042129\n",
       "22939       PYK  0.042086\n",
       "22940       TAX  0.148369\n",
       "22941   TMPRSS3  0.015149\n",
       "22942    XAGE1E  0.041072\n",
       "\n",
       "[22943 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Result\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(scores)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pharmaceutical-groove",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
