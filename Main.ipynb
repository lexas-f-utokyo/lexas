{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "curious-simpson",
   "metadata": {},
   "source": [
    "# Sentence Extraction from PMC articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "frequent-redhead",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lexas.sentence\n",
    "import lexas.relation_extraction\n",
    "import torch\n",
    "\n",
    "# Define the device to be used\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "demographic-greek",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "020193ab8c7d4587bbb9aab6e7db2b49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 1: Extracting result sections from the articles\n",
    "# The 'extract_results' function is used to extract sections of results from articles.\n",
    "lexas.sentence.extract_results(\n",
    "    article_dir=\"./articles/\",\n",
    "    output_file=\"./data/result_sections.txt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "signal-annex",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a94d9c2771a14df9843d22b9b5924319",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 2: Masking gene terms and experiments\n",
    "# The 'mask_gene_experiment' function is used to replace gene terms and experiments with MASK tokens in the text.\n",
    "lexas.sentence.mask_gene_experiment(\n",
    "    input_file_path=\"./data/result_sections.txt\",\n",
    "    output_file_path=\"./data/masked_sentences.txt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "actual-cookbook",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1517it [03:20,  7.55it/s]\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Relation extraction using BioBERT\n",
    "# The 'predict' function is used to predict relations using BioBERT model on the masked sentences.\n",
    "lexas.relation_extraction.predict(\n",
    "    device=device,\n",
    "    input_filepath=\"./data/masked_sentences.txt\",\n",
    "    output_filepath=\"./data/masked_sentences_bert.txt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "computational-panel",
   "metadata": {},
   "source": [
    "# Prediction model for genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "economic-campaign",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lexas.prediction\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eleven-uruguay",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "824it [00:00, 181261.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Extracting context from experiments\n",
    "# The 'extract_context_from_experiments' function processes the BioBERT predictions\n",
    "# and extracts the context in which each experiment mention was made.\n",
    "lexas.prediction.extract_context_from_experiments(\n",
    "    input_file=\"./data/masked_sentences_bert.txt\",\n",
    "    output_file=\"./data/experiments_for_xgboost.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "noble-contrast",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading categorical features...\n",
      "Loading numerical features...\n",
      "Loading string11_rwr.txt...\n",
      "Loading funcoup5_rwr.txt...\n",
      "Loading gosemsim.txt...\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Loading feature data\n",
    "# The 'feature_load' function is used to load feature data from various resources.\n",
    "lexas.prediction.feature_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "valuable-synthesis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of features:  ['10p', '10q', '11p', '11q', '12p', '12q', '13q', '14p', '14q', '15q']\n",
      "\n",
      "Features assigned to a gene:  ['10q', 'GO:0046686', 'GO:0065003', 'GO:0005634', 'GO:0030261', 'GO:0004674', 'GO:0000086', 'GO:0007098', 'GO:0060045', 'GO:0006281']\n",
      "\n",
      "Numerical features assigned to a gene:  dict_keys(['Tissue_expression', 'Cancer_expression', 'DepMap', 'Word2Vec'])\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Selecting features\n",
    "# The 'select_features' function is used to select the features to be used in the model.\n",
    "cat_use = ['Chromosome', 'GO', 'MGI', 'HPO', 'OMIM', 'TF', 'iRefIndex', 'Localization', 'WebSter']\n",
    "num_use = ['Tissue_expression', 'Cancer_expression', 'DepMap', 'Word2Vec']\n",
    "plus = [\"String\",\"Funcoup\",\"GOSemSim\"]\n",
    "feature_list, gene_cat, gene_num = lexas.prediction.select_features(cat_use, num_use)\n",
    "\n",
    "# Print feature information\n",
    "print(\"List of features: \", feature_list[:10])\n",
    "print(\"\\nFeatures assigned to a gene: \", gene_cat[\"CDK1\"][:10])\n",
    "print(\"\\nNumerical features assigned to a gene: \", gene_num.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "union-suggestion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing CSR matrix...  Done\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Constructing the CSR matrix\n",
    "# The 'construct_csr_matrix' function is used to transform the data into a format that can be processed by the XGBoost model.\n",
    "path_to_csv=\"./data/experiments_for_xgboost.csv\"\n",
    "posi_tuple, nega_tuple = lexas.prediction.generate_experiment_tuples(path_to_csv, 1990, 2018, negative_sampling=3)\n",
    "X, y = lexas.prediction.construct_csr_matrix(posi_tuple, nega_tuple, gene_cat, feature_list, gene_num, additional_features=plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "developmental-photography",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Train-Test split\n",
    "# The train_test_split function is used to split the data into training and testing sets for model training and evaluation.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "patient-double",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:02:31] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.68921\n",
      "[1]\tvalidation_0-logloss:0.68372\n",
      "[2]\tvalidation_0-logloss:0.67863\n",
      "[3]\tvalidation_0-logloss:0.67482\n",
      "[4]\tvalidation_0-logloss:0.67037\n",
      "[5]\tvalidation_0-logloss:0.66708\n",
      "[6]\tvalidation_0-logloss:0.66397\n",
      "[7]\tvalidation_0-logloss:0.66194\n",
      "[8]\tvalidation_0-logloss:0.65564\n",
      "[9]\tvalidation_0-logloss:0.65401\n",
      "[10]\tvalidation_0-logloss:0.65295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11]\tvalidation_0-logloss:0.65033\n",
      "[12]\tvalidation_0-logloss:0.64793\n",
      "[13]\tvalidation_0-logloss:0.64554\n",
      "[14]\tvalidation_0-logloss:0.64461\n",
      "[15]\tvalidation_0-logloss:0.64185\n",
      "[16]\tvalidation_0-logloss:0.64201\n",
      "[17]\tvalidation_0-logloss:0.63922\n",
      "[18]\tvalidation_0-logloss:0.64004\n",
      "[19]\tvalidation_0-logloss:0.63187\n",
      "[20]\tvalidation_0-logloss:0.63142\n",
      "[21]\tvalidation_0-logloss:0.62520\n",
      "[22]\tvalidation_0-logloss:0.62588\n",
      "[23]\tvalidation_0-logloss:0.61977\n",
      "[24]\tvalidation_0-logloss:0.61879\n",
      "[25]\tvalidation_0-logloss:0.61912\n",
      "[26]\tvalidation_0-logloss:0.61847\n",
      "[27]\tvalidation_0-logloss:0.61328\n",
      "[28]\tvalidation_0-logloss:0.61145\n",
      "[29]\tvalidation_0-logloss:0.61081\n",
      "[30]\tvalidation_0-logloss:0.60920\n",
      "[31]\tvalidation_0-logloss:0.60930\n",
      "[32]\tvalidation_0-logloss:0.60737\n",
      "[33]\tvalidation_0-logloss:0.60001\n",
      "[34]\tvalidation_0-logloss:0.60029\n",
      "[35]\tvalidation_0-logloss:0.59325\n",
      "[36]\tvalidation_0-logloss:0.59201\n",
      "[37]\tvalidation_0-logloss:0.59231\n",
      "[38]\tvalidation_0-logloss:0.59044\n",
      "[39]\tvalidation_0-logloss:0.58854\n",
      "[40]\tvalidation_0-logloss:0.58871\n",
      "[41]\tvalidation_0-logloss:0.58313\n",
      "[42]\tvalidation_0-logloss:0.58281\n",
      "[43]\tvalidation_0-logloss:0.58365\n",
      "[44]\tvalidation_0-logloss:0.58120\n",
      "[45]\tvalidation_0-logloss:0.57596\n",
      "[46]\tvalidation_0-logloss:0.57533\n",
      "[47]\tvalidation_0-logloss:0.57030\n",
      "[48]\tvalidation_0-logloss:0.57065\n",
      "[49]\tvalidation_0-logloss:0.56937\n",
      "[50]\tvalidation_0-logloss:0.56454\n",
      "[51]\tvalidation_0-logloss:0.56413\n",
      "[52]\tvalidation_0-logloss:0.56478\n",
      "[53]\tvalidation_0-logloss:0.56013\n",
      "[54]\tvalidation_0-logloss:0.56189\n",
      "[55]\tvalidation_0-logloss:0.56079\n",
      "[56]\tvalidation_0-logloss:0.55633\n",
      "[57]\tvalidation_0-logloss:0.55203\n",
      "[58]\tvalidation_0-logloss:0.55100\n",
      "[59]\tvalidation_0-logloss:0.55197\n",
      "[60]\tvalidation_0-logloss:0.54824\n",
      "[61]\tvalidation_0-logloss:0.54718\n",
      "[62]\tvalidation_0-logloss:0.54339\n",
      "[63]\tvalidation_0-logloss:0.54331\n",
      "[64]\tvalidation_0-logloss:0.53965\n",
      "[65]\tvalidation_0-logloss:0.53973\n",
      "[66]\tvalidation_0-logloss:0.53970\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Model Training\n",
    "# The XGBClassifier is used to train a model on the data. The model is then saved using the pickle library.\n",
    "model = xgb.XGBClassifier(\n",
    "    objective= \"binary:logistic\",\n",
    "    alpha=1e-3, \n",
    "    min_child_weight=3,\n",
    "    max_depth=10,\n",
    "    n_estimators=40000,\n",
    "    n_jobs=-1,\n",
    "    eta=0.03\n",
    ")\n",
    "model.fit(X_train, y_train, early_stopping_rounds=3, eval_set=[[X_test, y_test]])\n",
    "pickle.dump(model, open(\"./model/xgboost.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smoking-relationship",
   "metadata": {},
   "source": [
    "# Gene prediction for the next experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "measured-financing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import lexas.prediction\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load model\n",
    "# The 'pickle.load' function is used to load the previously saved XGBoost model.\n",
    "model_name = \"xgboost\"\n",
    "model_filepath = f\"./model/{model_name}.pickle\"\n",
    "if os.path.exists(model_filepath):\n",
    "    model = pickle.load(open(model_filepath,\"rb\"))\n",
    "else:\n",
    "    raise Exception(\"Model file does not exist: \" + model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "encouraging-margin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Generate scores\n",
    "# The 'generate_scores' function is used to score all genes in relation to the query using the XGBoost model.\n",
    "query = \"CEP152\"\n",
    "scores = lexas.prediction.generate_scores(query, model_name, model, gene_cat, feature_list, gene_num, additional_features=plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "chinese-asbestos",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>xgboost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14237</th>\n",
       "      <td>PIFO</td>\n",
       "      <td>0.620295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3418</th>\n",
       "      <td>CNN2</td>\n",
       "      <td>0.599426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5346</th>\n",
       "      <td>ESRRA</td>\n",
       "      <td>0.595573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9774</th>\n",
       "      <td>LYZ</td>\n",
       "      <td>0.593850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13765</th>\n",
       "      <td>PARP3</td>\n",
       "      <td>0.587560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22774</th>\n",
       "      <td>HP</td>\n",
       "      <td>0.585280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5433</th>\n",
       "      <td>F2</td>\n",
       "      <td>0.579334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22326</th>\n",
       "      <td>DBI</td>\n",
       "      <td>0.572630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18622</th>\n",
       "      <td>STON1</td>\n",
       "      <td>0.572630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17483</th>\n",
       "      <td>SLX1B-SULT1A4</td>\n",
       "      <td>0.571906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Symbol   xgboost\n",
       "14237           PIFO  0.620295\n",
       "3418            CNN2  0.599426\n",
       "5346           ESRRA  0.595573\n",
       "9774             LYZ  0.593850\n",
       "13765          PARP3  0.587560\n",
       "22774             HP  0.585280\n",
       "5433              F2  0.579334\n",
       "22326            DBI  0.572630\n",
       "18622          STON1  0.572630\n",
       "17483  SLX1B-SULT1A4  0.571906"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Display result\n",
    "# The result is displayed as a DataFrame sorted by the XGBoost score in descending order.\n",
    "output_dir = f\"./result/{model_name}\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "df = pd.DataFrame(scores)\n",
    "df.to_csv(os.path.join(output_dir,f\"{query}.csv\"),index=False)\n",
    "df.sort_values(model_name, ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "patent-thickness",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>xgboost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2586</th>\n",
       "      <td>CCNQ</td>\n",
       "      <td>0.771731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12765</th>\n",
       "      <td>NR1D1</td>\n",
       "      <td>0.769125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8385</th>\n",
       "      <td>ITGB3</td>\n",
       "      <td>0.767917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16049</th>\n",
       "      <td>RNF207</td>\n",
       "      <td>0.761760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16336</th>\n",
       "      <td>RTL8A</td>\n",
       "      <td>0.761760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5502</th>\n",
       "      <td>FAM43A</td>\n",
       "      <td>0.749447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17364</th>\n",
       "      <td>SLC35E4</td>\n",
       "      <td>0.749447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991</th>\n",
       "      <td>CETN4P</td>\n",
       "      <td>0.749447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8451</th>\n",
       "      <td>JDP2</td>\n",
       "      <td>0.749447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3823</th>\n",
       "      <td>CST3</td>\n",
       "      <td>0.749447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Symbol   xgboost\n",
       "2586      CCNQ  0.771731\n",
       "12765    NR1D1  0.769125\n",
       "8385     ITGB3  0.767917\n",
       "16049   RNF207  0.761760\n",
       "16336    RTL8A  0.761760\n",
       "...        ...       ...\n",
       "5502    FAM43A  0.749447\n",
       "17364  SLC35E4  0.749447\n",
       "2991    CETN4P  0.749447\n",
       "8451      JDP2  0.749447\n",
       "3823      CST3  0.749447\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(model_name, ascending=False)[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dental-dallas",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
