{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "curious-simpson",
   "metadata": {},
   "source": [
    "# Sentence Extraction from PMC articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "frequent-redhead",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lexas.sentence\n",
    "import lexas.relation_extraction\n",
    "import torch\n",
    "\n",
    "# Define the device to be used\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "demographic-greek",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "020193ab8c7d4587bbb9aab6e7db2b49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 1: Extracting result sections from the articles\n",
    "# The 'extract_results' function is used to extract sections of results from articles.\n",
    "lexas.sentence.extract_results(\n",
    "    article_dir=\"./articles/\",\n",
    "    output_file=\"./data/result_sections.txt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "signal-annex",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a94d9c2771a14df9843d22b9b5924319",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 2: Masking gene terms and experiments\n",
    "# The 'mask_gene_experiment' function is used to replace gene terms and experiments with MASK tokens in the text.\n",
    "lexas.sentence.mask_gene_experiment(\n",
    "    input_file_path=\"./data/result_sections.txt\",\n",
    "    output_file_path=\"./data/masked_sentences.txt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "actual-cookbook",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1517it [03:20,  7.55it/s]\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Relation extraction using BioBERT\n",
    "# The 'predict' function is used to predict relations using BioBERT model on the masked sentences.\n",
    "lexas.relation_extraction.predict(\n",
    "    device=device,\n",
    "    input_filepath=\"./data/masked_sentences.txt\",\n",
    "    output_filepath=\"./data/masked_sentences_bert.txt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "computational-panel",
   "metadata": {},
   "source": [
    "# Prediction model for genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "economic-campaign",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lexas.prediction\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eleven-uruguay",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "824it [00:00, 181261.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Extracting context from experiments\n",
    "# The 'extract_context_from_experiments' function processes the BioBERT predictions\n",
    "# and extracts the context in which each experiment mention was made.\n",
    "lexas.prediction.extract_context_from_experiments(\n",
    "    input_file=\"./data/masked_sentences_bert.txt\",\n",
    "    output_file=\"./data/experiments_for_xgboost.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "noble-contrast",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading categorical features...\n",
      "Loading numerical features...\n",
      "Loading string11_rwr.txt...\n",
      "Loading funcoup5_rwr.txt...\n",
      "Loading gosemsim.txt...\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Loading feature data\n",
    "# The 'feature_load' function is used to load feature data from various resources.\n",
    "lexas.prediction.feature_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "valuable-synthesis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of features:  ['10p', '10q', '11p', '11q', '12p', '12q', '13q', '14p', '14q', '15q']\n",
      "\n",
      "Features assigned to a gene:  ['10q', 'GO:0046686', 'GO:0065003', 'GO:0005634', 'GO:0030261', 'GO:0004674', 'GO:0000086', 'GO:0007098', 'GO:0060045', 'GO:0006281']\n",
      "\n",
      "Numerical features assigned to a gene:  dict_keys(['Tissue_expression', 'Cancer_expression', 'DepMap', 'Word2Vec'])\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Selecting features\n",
    "# The 'select_features' function is used to select the features to be used in the model.\n",
    "cat_use = ['Chromosome', 'GO', 'MGI', 'HPO', 'OMIM', 'TF', 'iRefIndex', 'Localization', 'WebSter']\n",
    "num_use = ['Tissue_expression', 'Cancer_expression', 'DepMap', 'Word2Vec']\n",
    "plus = [\"String\",\"Funcoup\",\"GOSemSim\"]\n",
    "feature_list, gene_cat, gene_num = lexas.prediction.select_features(cat_use, num_use)\n",
    "\n",
    "# Print feature information\n",
    "print(\"List of features: \", feature_list[:10])\n",
    "print(\"\\nFeatures assigned to a gene: \", gene_cat[\"CDK1\"][:10])\n",
    "print(\"\\nNumerical features assigned to a gene: \", gene_num.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "union-suggestion",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "793it [00:00, 757995.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing CSR matrix...  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Constructing the CSR matrix\n",
    "# The 'construct_csr_matrix' function is used to transform the data into a format that can be processed by the XGBoost model.\n",
    "path_to_csv=\"./data/experiments_for_xgboost.csv\"\n",
    "posi_tuple, nega_tuple = lexas.prediction.generate_experiment_tuples(path_to_csv, 1990, 2018, negative_sampling=3)\n",
    "X, y = lexas.prediction.construct_csr_matrix(posi_tuple, nega_tuple, gene_cat, feature_list, gene_num, additional_features=plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "developmental-photography",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Train-Test split\n",
    "# The train_test_split function is used to split the data into training and testing sets for model training and evaluation.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "patient-double",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:29:56] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.68517\n",
      "[1]\tvalidation_0-logloss:0.68236\n",
      "[2]\tvalidation_0-logloss:0.67584\n",
      "[3]\tvalidation_0-logloss:0.66625\n",
      "[4]\tvalidation_0-logloss:0.65965\n",
      "[5]\tvalidation_0-logloss:0.65783\n",
      "[6]\tvalidation_0-logloss:0.65276\n",
      "[7]\tvalidation_0-logloss:0.65167\n",
      "[8]\tvalidation_0-logloss:0.64617\n",
      "[9]\tvalidation_0-logloss:0.64540\n",
      "[10]\tvalidation_0-logloss:0.63756\n",
      "[11]\tvalidation_0-logloss:0.63376\n",
      "[12]\tvalidation_0-logloss:0.63340\n",
      "[13]\tvalidation_0-logloss:0.63384\n",
      "[14]\tvalidation_0-logloss:0.63589\n",
      "[15]\tvalidation_0-logloss:0.63258\n",
      "[16]\tvalidation_0-logloss:0.63111\n",
      "[17]\tvalidation_0-logloss:0.62823\n",
      "[18]\tvalidation_0-logloss:0.62956\n",
      "[19]\tvalidation_0-logloss:0.62701\n",
      "[20]\tvalidation_0-logloss:0.62595\n",
      "[21]\tvalidation_0-logloss:0.62376\n",
      "[22]\tvalidation_0-logloss:0.62526\n",
      "[23]\tvalidation_0-logloss:0.62813\n",
      "[24]\tvalidation_0-logloss:0.62342\n",
      "[25]\tvalidation_0-logloss:0.62498\n",
      "[26]\tvalidation_0-logloss:0.62800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./model/xgboost.joblib']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 6: Model Training\n",
    "# The XGBClassifier is used to train a model on the data. The model is then saved using the joblib library.\n",
    "model = xgb.XGBClassifier(\n",
    "    objective= \"binary:logistic\",\n",
    "    alpha=1e-3, \n",
    "    min_child_weight=3,\n",
    "    max_depth=10,\n",
    "    n_estimators=40000,\n",
    "    n_jobs=-1,\n",
    "    eta=0.03\n",
    ")\n",
    "model.fit(X_train, y_train, early_stopping_rounds=3, eval_set=[[X_test, y_test]])\n",
    "\n",
    "# Save the model to a file\n",
    "from joblib import dump\n",
    "model_path = \"./model/xgboost.joblib\"\n",
    "dump(model, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smoking-relationship",
   "metadata": {},
   "source": [
    "# Gene prediction for the next experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "measured-financing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import lexas.prediction\n",
    "import pandas as pd\n",
    "from joblib import load\n",
    "\n",
    "# Step 1: Load model\n",
    "model_name = \"xgboost\"\n",
    "\n",
    "model_filepath = f\"./model/{model_name}.joblib\"\n",
    "\n",
    "if os.path.exists(model_filepath):\n",
    "    model = load(model_filepath)\n",
    "else:\n",
    "    raise Exception(\"Model file does not exist: \" + model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "encouraging-margin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Generate scores\n",
    "# The 'generate_scores' function is used to score all genes in relation to the query using the XGBoost model.\n",
    "query = \"CEP152\"\n",
    "scores = lexas.prediction.generate_scores(query, model_name, model, gene_cat, feature_list, gene_num, additional_features=plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "chinese-asbestos",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>xgboost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1799</th>\n",
       "      <td>BUB1B-PAK6</td>\n",
       "      <td>0.649517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17144</th>\n",
       "      <td>SLC8A3</td>\n",
       "      <td>0.649517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5551</th>\n",
       "      <td>FAM86C1P</td>\n",
       "      <td>0.649517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17598</th>\n",
       "      <td>SMTNL2</td>\n",
       "      <td>0.649517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6965</th>\n",
       "      <td>GRPEL1</td>\n",
       "      <td>0.637327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6050</th>\n",
       "      <td>FN1</td>\n",
       "      <td>0.637327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15751</th>\n",
       "      <td>REM1</td>\n",
       "      <td>0.637327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11877</th>\n",
       "      <td>MST1R</td>\n",
       "      <td>0.637327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7753</th>\n",
       "      <td>IARS2</td>\n",
       "      <td>0.637327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6889</th>\n",
       "      <td>GPRIN2</td>\n",
       "      <td>0.637327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Symbol   xgboost\n",
       "1799   BUB1B-PAK6  0.649517\n",
       "17144      SLC8A3  0.649517\n",
       "5551     FAM86C1P  0.649517\n",
       "17598      SMTNL2  0.649517\n",
       "6965       GRPEL1  0.637327\n",
       "6050          FN1  0.637327\n",
       "15751        REM1  0.637327\n",
       "11877       MST1R  0.637327\n",
       "7753        IARS2  0.637327\n",
       "6889       GPRIN2  0.637327"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Display result\n",
    "# The result is displayed as a DataFrame sorted by the XGBoost score in descending order.\n",
    "output_dir = f\"./result/{model_name}\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "df = pd.DataFrame(scores)\n",
    "df.to_csv(os.path.join(output_dir,f\"{query}.csv\"),index=False)\n",
    "df.sort_values(model_name, ascending=False)[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
